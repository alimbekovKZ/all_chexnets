{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet with CheXpert and MIMIC-CXR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will set uncertainty u = 1 for the first trial run.\n",
    "\n",
    "The CheXpert paper uses an Adam optimizer withh default beta and constant learning rate = 1e-4, uses batch norm with 16 img-sized batches, 3 epochs, and saves checkpoint every 4800 iterations.\n",
    "\n",
    "The original DenseNet paper used Nesterov momentum without dampening, SGD, also learning rate decay and weight decay. They use Batch normalization and dropout = 0.2.  With their ImageNet model they used mini-batch gradient descent with no dropout.\n",
    "\n",
    "Of the papers which didn't use Adam, or which used it the right way when combined with weight decay, many failed to realize that, when used together with batch norm, weight decay and learning rate decay are no more independent. This is fully explained in \"Decoupled Weight Decay Regularization\"\n",
    "\n",
    "I will start with the AdamWR algorithm, which has a corrected weight decay with a normalized batch norm, and uses cosine annealing to attempt to improve the speed of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, TensorDataset, Sampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.insert(0, \"./chex\")\n",
    "import densenetpython\n",
    "import adamw\n",
    "import cosine_scheduler\n",
    "import compare_auc_delong_xu \n",
    "import h5py\n",
    "import zarr\n",
    "# torch.multiprocessing.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'train.csv', 'val.csv', 'CheXpert-v1.0.zip', 'valid', 'train_uones_inp224_processed.h5', 'val_uones_inp224_processed.h5']\n",
      "(223414, 19) (234, 19)\n"
     ]
    }
   ],
   "source": [
    "#Top level data directory (can be 'CheXpert-v1.0-small', 'CheXpert-v1.0', 'mimic-cxr')\n",
    "root_dir = 'Data/'\n",
    "which_data = 'CheXpert-v1.0'\n",
    "data_dir = f'{root_dir}{which_data}'\n",
    "\n",
    "#Data is split into two sets (may later create a training-dev set)\n",
    "phases = ['train', 'val']\n",
    "\n",
    "#Path to csvfiles on training and validation data\n",
    "csvpath = {phase: '{}/{}.csv'.format(data_dir, phase) for phase in phases}\n",
    "\n",
    "#Load data into dictionary of two Pandas DataFrames\n",
    "dframe = {phase: pd.read_csv(csvpath[phase]) for phase in phases}\n",
    "\n",
    "#Calculate sizes\n",
    "dataset_sizes = {phase:len(dframe[phase]) for phase in phases}\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "print(dframe['train'].shape, dframe['val'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [efficient-densenet, resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 14\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 3\n",
    "\n",
    "#Number of minibatches to pass before printing out metrics\n",
    "checkpoint = 200\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "\n",
    "#The number of training samples\n",
    "num_samples = dframe['train'].shape[0]\n",
    "\n",
    "#Class names that will be predicted\n",
    "class_names = dframe['train'].iloc[:,5:].columns\n",
    "\n",
    "#indices we will calculate AUC for, as in the CheXpert paper\n",
    "competition_tasks = torch.ByteTensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0])\n",
    "\n",
    "#Which approach to use when dealing with uncertain labels (as detailed in the CheXpert paper)\n",
    "u_approach = 'ones'\n",
    "\n",
    "# Pick the model\n",
    "model_name = 'resnet'\n",
    "\n",
    "#Using pretrained weights\n",
    "use_pretrained = True\n",
    "\n",
    "#filename for outputs\n",
    "filename = f'{which_data}_{model_name}_{u_approach}_{batch_size}'\n",
    "\n",
    "#Calculating weighting for imbalanced classes (input in loss criterion)\n",
    "df = dframe['train'].iloc[:,5:].copy()\n",
    "df = df.replace(-1,0)\n",
    "pos_weight = torch.Tensor([df[cl].sum()/df.shape[0] for cl in class_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('Using CUDA') if use_cuda else print('Using CPU')\n",
    "\n",
    "print(torch.cuda.memory_cached()/1e9)\n",
    "print(torch.cuda.max_memory_cached()/1e9)\n",
    "print(torch.cuda.memory_allocated()/1e9)\n",
    "print(torch.cuda.max_memory_allocated()/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, competition_tasks, \n",
    "                num_epochs=25, max_fpr=None, u_approach=None, is_inception=False, checkpoint=200):\n",
    "    \n",
    "    since = time.time() \n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_auc = 0.0\n",
    "    missing = 0;\n",
    "    losses = {'train':[],'val':[]}; \n",
    "    accuracy = {'train':[],'val':[]}; \n",
    "    variances = {'train':[],'val':[]}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0; running_auc = 0.0; running_var = 0.0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    if u_approach == \"ignore\":\n",
    "                        mask = labels.lt(0) #select u labels (-1)\n",
    "                        loss = torch.sum(loss.masked_select(mask)) #mask out uncertain labels\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "#                         scheduler.batch_step() #USE WITH DENSENET and other scheduler\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                #select subset of 5 pathologies of interest\n",
    "                labels_sub = labels[:,competition_tasks].cpu().squeeze().numpy()\n",
    "                preds_sub = outputs[:,competition_tasks].detach().cpu().squeeze().numpy()\n",
    "\n",
    "                if u_approach == \"ignore\":\n",
    "                    #mask out the negative values\n",
    "                    mask_sub = (labels_sub>-1) \n",
    "                    for j in range(labels_sub.shape[1]):     \n",
    "                        label = labels_sub[:,j]\n",
    "                        pred = preds_sub[:,j]\n",
    "                        m = mask_sub[:,j]\n",
    "                        label = label[m]; pred = pred[m]\n",
    "                        try:\n",
    "                            tmp = compare_auc_delong_xu.delong_roc_variance(label, pred)\n",
    "                            running_auc += tmp[0]\n",
    "                            running_var += np.nansum(tmp[1])\n",
    "                        except:\n",
    "                            missing += 1;\n",
    "                            continue\n",
    "                else:\n",
    "                    for j in range(labels_sub.shape[1]):     \n",
    "                        label = labels_sub[:,j]\n",
    "                        pred = preds_sub[:,j]\n",
    "                        tmp = compare_auc_delong_xu.delong_roc_variance(label, pred)\n",
    "                        running_auc += tmp[0]\n",
    "                        running_var += np.nansum(tmp[1])\n",
    "\n",
    "#                 if (i+1) % checkpoint == 0:    # print every 'checkpoint' mini-batches\n",
    "                if (i+1) % 2 == 0:    # print every 'checkpoint' mini-batches\n",
    "#                     print('Missed {}'.format(missing))\n",
    "                    print(f'{phase} Loss: {running_loss / (i+1)} DeLong AUC: {running_auc / (labels_sub.shape[1] * (i+1) * batch_size)} Variance: {running_var / (labels_sub.shape[1] * (i+1) * batch_size)}')\n",
    "                    \n",
    "                    losses[phase].append(running_loss / ((i+1) * batch_size))\n",
    "                    accuracy[phase].append(running_auc / (labels_sub.shape[1] * (i+1) * batch_size))\n",
    "                    variances[phase].append(running_var / (labels_sub.shape[1] * (i+1) * batch_size))\n",
    "                    break\n",
    "                    \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_auc = running_auc / (dataset_sizes[phase] * labels_sub.shape[1])\n",
    "            epoch_var = running_var / (dataset_sizes[phase] * labels_sub.shape[1])\n",
    "            print(f'{phase} Epoch Loss: {epoch_loss} Epoch AUC: {epoch_auc} Epoch Variance: {epoch_var}')\n",
    "            #With a small validation set would otherwise get no recorded values so:\n",
    "            if phase == 'val':\n",
    "                losses[phase].append(epoch_loss)\n",
    "                accuracy[phase].append(epoch_auc)\n",
    "                variances[phase].append(epoch_var)  \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_auc > best_auc:\n",
    "                best_auc = epoch_auc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "    print(f'Best val AUC: {best_auc}')\n",
    "    print(f'Missed {missing} examples.')\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    metrics = (losses, accuracy, variances)\n",
    "#     for phase in ['train', 'val']:\n",
    "#         with open(f'metrics/{filename}_{phase}.txt','w+') as f:\n",
    "#             for idx in len(losses[phase]):\n",
    "#                 f.write(f'{losses[phase][idx]} {accuracy[phase][idx]} {variances[phase][idx]}\\n')\n",
    "\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    if model_name == \"efficient-densenet\":\n",
    "        \"\"\"memory-efficient densenet - https://github.com/gpleiss/efficient_densenet_pytorch\n",
    "        \"\"\"\n",
    "        # # \n",
    "        growth_rate  = 32    #(int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config = [6, 12, 24, 16]     #(list of 3 or 4 ints) - how many layers in each pooling block\n",
    "        compression = 0.5   #Reduction in size\n",
    "        num_init_features = 2 * growth_rate    #(int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size =  4   #(int) - mult. factor for number of bottle neck layers (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate = 0.     #(float) - dropout rate after each dense layer\n",
    "        small_inputs = False     #(bool) - set to True if images are 32x32. Otherwise assumes images are larger.\n",
    "        efficient = True     #(bool) - set to True to use checkpointing. Much more memory efficient, but slower.\n",
    "        model_ft = densenet.DenseNet(growth_rate=growth_rate, block_config=block_config, compression=compression, \n",
    "                         num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate, num_classes=num_classes, \n",
    "                        small_inputs=small_inputs, efficient=efficient)\n",
    "        if use_pretrained:\n",
    "            state_dict = torch.load('chexpredict/densenet121_effi.pth')\n",
    "            model.load_state_dict(state_dict, strict=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    \"\"\"CheXpert dataset.\"\"\"\n",
    "    def __init__(self, data_dir, phase, u_approach, num_samples, hdf5path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chex_frame (DataFrame): Train or validation data\n",
    "            root_dir (string): Directory with all the images.\n",
    "            tforms (Torch Transform): pre-processing transforms\n",
    "            targets (DataFrame): Modifies labels depending on u_approach\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.phase = phase\n",
    "        self.u_approach = u_approach\n",
    "        self.num_samples = num_samples\n",
    "        self.hdf5path = hdf5path\n",
    "        self.hdf5 = None\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         if(self.hdf5 is None): #open in thread\n",
    "#             self.hdf5 = h5py.File(f'{self.hdf5path}', 'r')\n",
    "#         img = self.hdf5[(f\"X{idx}\")]\n",
    "#         labels = self.hdf5[(f\"y{idx}\")]           \n",
    "#         img = torch.FloatTensor(img)\n",
    "#         labels = torch.FloatTensor(labels)\n",
    "#         return (img, labels)\n",
    "    \n",
    "#         with h5py.File(self.hdf5path, 'r') as hf:  \n",
    "        with h5py.File(self.hdf5path, 'r', libver='latest', swmr=True) as hf:\n",
    "            img = hf[(f\"X{idx}\")][()]\n",
    "            labels = hf[(f\"y{idx}\")][()]           \n",
    "#             img = torch.FloatTensor(img)\n",
    "#             labels = torch.FloatTensor(labels)\n",
    "            return np.float32(img), np.float32(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "#preprocess target labels before placing in dataloader\n",
    "labels_array = {phase: dframe[phase].iloc[:,5:].copy().fillna(0) for phase in phases}\n",
    "\n",
    "for phase in labels_array.keys():\n",
    "    if u_approach == 'ones':\n",
    "        labels_array[phase] = labels_array[phase].replace(-1,1)\n",
    "    elif u_approach == 'zeros':\n",
    "        labels[phase] = labels_array[phase].replace(-1,0)\n",
    "    labels_array[phase] = torch.FloatTensor(labels_array[phase].to_numpy()) #needed when using cross-entropy loss\n",
    "\n",
    "#Transforms to perform on images\n",
    "tforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])}\n",
    "hdf5paths = {phase: f'{data_dir}/{phase}_u{u_approach}_inp{input_size}_processed.h5' for phase in phases}\n",
    "# Create the datasets\n",
    "datasets = {phase: CheXpertDataset(data_dir=data_dir, phase=phase, u_approach=u_approach, num_samples=dataset_sizes[phase], hdf5path=hdf5paths[phase]) for phase in phases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 0, 140897484)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def proc_images(img_paths, labels_array, data_dir, u_approach, input_size, phases=['train', 'val'], tforms=None):\n",
    "    \"\"\"\n",
    "    Saves compressed, resized images as HDF5 datsets\n",
    "    Returns\n",
    "        data.h5, where each dataset is an image or class label\n",
    "        e.g. X23,y23 = image and corresponding class labels\n",
    "    \"\"\"\n",
    "    for phase in phases:\n",
    "        print(f'Processing {phase} files...')\n",
    "        with h5py.File(f'{data_dir}/{phase}_u{u_approach}_inp{input_size}_processed.h5', 'w') as hf: \n",
    "            for i,img_path in enumerate(img_paths[phase]):     \n",
    "                if i % 2000 == 0:\n",
    "                    print(f\"{i} images processed\")\n",
    "\n",
    "                # Images\n",
    "                #Using Pillow-SIMD rather than Pillow\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                if tforms:\n",
    "                    img = tforms[phase](img)\n",
    "                Xset = hf.create_dataset(\n",
    "                    name=f\"X{i}\",\n",
    "                    data=img,\n",
    "                    shape=(3, input_size, input_size),\n",
    "                    maxshape=(3, input_size, input_size),\n",
    "                    compression=\"lzf\",\n",
    "                    shuffle=\"True\")\n",
    "               # Labels\n",
    "                yset = hf.create_dataset(\n",
    "#                     name=f\"y{i}\",\n",
    "                    name=f\"y{i}\",\n",
    "                    data = labels_array[phase][i,:],\n",
    "                    shape=(num_classes,),\n",
    "                    maxshape=(num_classes,),\n",
    "                    compression=\"lzf\",\n",
    "                    shuffle=\"True\",\n",
    "                    dtype=\"i1\")\n",
    "    print('Finished!')\n",
    "try:\n",
    "    os.path.isfile(f'{data_dir}/{phases[0]}_u{u_approach}_inp{input_size}_processed.h5') \n",
    "    os.path.isfile(f'{data_dir}/{phases[1]}_u{u_approach}_inp{input_size}_processed.h5') \n",
    "except:\n",
    "    img_paths = {phase: root_dir + dframe[phase].iloc[:,0] for phase in phases}\n",
    "    proc_images(img_paths, labels_array, data_dir, u_approach, input_size, phases=phases, tforms=tforms)\n",
    "\n",
    "if not os.path.isfile(f'{data_dir}/{phases[1]}_u{u_approach}_inp{input_size}_processed.zarr'):\n",
    "    source = h5py.File(f'{data_dir}/{phases[1]}_u{u_approach}_inp{input_size}_processed.h5', mode='r')\n",
    "    dest = zarr.open_group(f'{data_dir}/{phases[1]}_u{u_approach}_inp{input_size}_processed.zarr', mode='w')\n",
    "    zarr.copy_all(source, dest, log=sys.stdout)\n",
    "if not os.path.isfile(f'{data_dir}/{phases[0]}_u{u_approach}_inp{input_size}_processed.zarr'):\n",
    "    source = h5py.File(f'{data_dir}/{phases[0]}_u{u_approach}_inp{input_size}_processed.h5', mode='r')\n",
    "    dest = zarr.open_group(f'{data_dir}/{phases[0]}_u{u_approach}_inp{input_size}_processed.zarr', mode='w')\n",
    "    zarr.copy_all(source, dest, log=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Accounting for imbalanced classes\n",
    "# df = dframe['train'].iloc[:,5:].fillna(0).copy()\n",
    "# # df = df.replace(-1, np.nan)\n",
    "\n",
    "# #Get a list of the number of positive, negative, and uncertain samples for each class\n",
    "# class_sample_count = [df[df==t].count() for t in [-1, 0, 1]]\n",
    "# #Use this to calculate the weight for positive, negative, and uncertain samples for each class\n",
    "# weights = [num_classes * class_sample_count[t] * (1 / num_samples) for t in range(len(class_sample_count))]\n",
    "# #Create list of weights as long as the dataset, squeeze to put in sequence? \n",
    "# sample_weights = weights[0] * (df==-1) + weights[1] * (df==0) + weights[2] * (df==1)\n",
    "# sample_weights.head(3)\n",
    "# sample_weights = sample_weights.to_numpy()\n",
    "# print(weights[1])\n",
    "# #Load into sampler\n",
    "# sampler = None\n",
    "# # sampler = torch.utils.data.WeightedRandomSampler(sample_weights, 1, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "num_workers = torch.get_num_threads()\n",
    "# num_workers = 0\n",
    "params = {'train': {'batch_size': batch_size,\n",
    "                   'shuffle': True,\n",
    "                   'num_workers': num_workers,\n",
    "                   'pin_memory':True}, #Trying this out once more to see if it helps\n",
    "#                    'sampler': sampler},\n",
    "          'val': {'batch_size': batch_size,\n",
    "                 'num_workers': num_workers,\n",
    "                 'pin_memory':True}}\n",
    "# if params['train']['sampler'] is not None:\n",
    "#     params['train']['shuffle'] = False\n",
    "dataloaders = {phase: DataLoader(datasets[phase], **params[phase]) for phase in phases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Show transformed images\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(len(datasets['val'])):\n",
    "#     sample = datasets['val'][i]\n",
    "# #     print(i, sample[0].shape, sample[1].shape)\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "#     plt.imshow(sample[0][0,:,:])\n",
    "\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Checking for shuffling (or not)\n",
    "# times = []\n",
    "# t0 = time.time()\n",
    "# for i, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "#     if i < 1:\n",
    "# #         print(i)\n",
    "#         times.append(time.time()-t0)\n",
    "#         t0 = time.time()\n",
    "# #         print('Time to load/transform: {:.3f} s'.format(t1-t0))\n",
    "# #         print(inputs[1].size(0))\n",
    "# #         target = inputs[1]\n",
    "# #         target[target==-1]=0\n",
    "# #         print(torch.sum(target,dim=0))\n",
    "# #         target = inputs[1][:,competition_tasks]\n",
    "# #         target[target==-1]=0\n",
    "# #         print(torch.sum(target,dim=0))\n",
    "# #         print(target.shape)\n",
    "        \n",
    "# #     else:\n",
    "#         break\n",
    "# print('Average time to load up data: {} s'.format(np.round(np.mean(times),4)))\n",
    "# #With batch size of 64\n",
    "# # 3.6-4 s for hdf5 datasets\n",
    "# # 5.3-6 s for original method with Pillow-SIMD\n",
    "# # 5.5-6.4 s for alternative PIL method\n",
    "# # 5.7-6.1 s for cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function to show a batch\n",
    "# def show_img_batch(sample_batched):\n",
    "#     \"\"\"Show image with labels for a batch of samples.\"\"\"\n",
    "#     images_batch, labels_batch = \\\n",
    "#             sample_batched[0], sample_batched[1]\n",
    "#     batch_size = len(images_batch)\n",
    "#     im_size = images_batch.size(2)\n",
    "\n",
    "#     grid = utils.make_grid(images_batch)\n",
    "#     plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(dataloaders['train']):\n",
    "#     print(i_batch, sample_batched[0].size(), sample_batched[1].size())\n",
    "    \n",
    "#     # observe 4th batch and stop.\n",
    "#     if i_batch == 3:\n",
    "#         plt.figure()\n",
    "#         show_img_batch(sample_batched)\n",
    "#         plt.axis('off')\n",
    "#         plt.ioff()\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_ft.load_state_dict(torch.load('models/{}.pt'.format(filename))) #load weights if already completed\n",
    "except:\n",
    "    print('Starting from scratch..')\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "if u_approach == 'ignore': #Use masked binary cross-entropy for first run\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none',pos_weight=pos_weight).to(device)\n",
    "else:\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum',pos_weight=pos_weight).to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# # Pick AdamW optimizer - https://github.com/mpyrozhok/adamwr\n",
    "# optimizer = adamw.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# epoch_size = np.round(num_samples / batch_size) # number of training examples/batch size\n",
    "# #Cosine annealing: adjusting on batch update rather than epoch - https://github.com/mpyrozhok/adamwr\n",
    "# scheduler = cosine_scheduler.CosineLRWithRestarts(optimizer, batch_size, epoch_size, restart_period=5, t_mult=1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_ft\n",
    "# optimizer = optimizer_ft\n",
    "# scheduler = exp_lr_scheduler\n",
    "# is_inception = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, metrics = train_model(model_ft, dataloaders, criterion, optimizer_ft, exp_lr_scheduler, competition_tasks, \n",
    "                       num_epochs=num_epochs, u_approach=u_approach, is_inception=(model_name==\"inception\"), checkpoint=checkpoint)\n",
    "torch.save(model_ft.state_dict(), f'models/{filename}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualizing model predictions\n",
    "# def visualize_model(model, num_images=6):\n",
    "#     tform = transforms.Compose([transforms.functional.to_pil_image,\n",
    "#                                 transforms.functional.to_grayscale])\n",
    "#     was_training = model.training\n",
    "#     model.eval()\n",
    "#     images_so_far = 0\n",
    "#     fig = plt.figure()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             for j in range(inputs.size()[0]):\n",
    "#                 images_so_far += 1\n",
    "#                 ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "#                 ax.axis('off')\n",
    "#                 img = tform(inputs[j].cpu())\n",
    "#                 ax.set_title('First prediction: {}'.format(class_names[preds[j]]))\n",
    "#                 plt.imshow(img)\n",
    "\n",
    "#                 if images_so_far == num_images:\n",
    "#                     model.train(mode=was_training)\n",
    "#                     return\n",
    "#         model.train(mode=was_training)\n",
    "        \n",
    "        \n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "    \n",
    "# model_ft.load_state_dict(torch.load(f'models/{filename}.pt')) #load new weights\n",
    "# model_ft.to(device)\n",
    "\n",
    "# visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Path to csvfiles on training and validation data\n",
    "\n",
    "\n",
    "# #Load data into dictionary of two Pandas DataFrames\n",
    "# mf = {phase: pd.read_csv(metricspath[phase]) for phase in phases}\n",
    "\n",
    "# plt.title(\"AUC vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"DeLong AUC\")\n",
    "# plt.plot(range(1,num_epochs+1),mf['train'],label=\"train\")\n",
    "# plt.plot(range(1,num_epochs+1),mf['val'],label=\"val\")\n",
    "# plt.ylim((0,1.))\n",
    "# # plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torchvision\n",
    "# from torchvision import models, transforms\n",
    "# print(\"PyTorch Version: \",torch.__version__)\n",
    "# print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# from PIL import Image\n",
    "\n",
    "# #Initialize model\n",
    "# filename = \"\"\n",
    "# num_classes = 14\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# #Load trained weights\n",
    "# model_ft.load_state_dict(torch.load('models/{}.pt'.format(filename)))  \n",
    "# model_ft.to(device)\n",
    "\n",
    "# def predict(input_csv_name, output_csv_name, model):\n",
    "#     '''\n",
    "#     The input-data-csv-file path will point to a file which is structured exactly like \n",
    "#     valid_image_paths.csv, ie where each line is of the form \n",
    "#     CheXpert-v1.0/{valid,test}/<STUDYTYPE>/<PATIENT>/<STUDY>/<IMAGE>\n",
    "#     '''\n",
    "#     #Input series of image paths\n",
    "#     img_paths = pd.read_csv(input_csv_name)\n",
    "    \n",
    "#     #Output file predictions for the following competition tasks:\n",
    "#     col_names = ['Study', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "    \n",
    "#     #Output dataframe\n",
    "#     output_csv = pd.DataFrame(index=range(1,len(img_paths)), columns=col_names)\n",
    "    \n",
    "#     #Predicting for dummy validation and actual test data:\n",
    "#     phases = ['valid', 'test']\n",
    "        \n",
    "#     #Image preprocessing\n",
    "#     tforms = transforms.Compose([\n",
    "#         transforms.Resize(input_size),\n",
    "#         transforms.CenterCrop(input_size),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    \n",
    "#     #RegEx to determine study number and whether in validation or test data \n",
    "#     pattern = re.compile(r'(CheXpert-v1.0\\/\\w+\\/\\w+\\/study\\d)\\/view\\d_\\w+\\.jpg')\n",
    "        \n",
    "#     was_training = model.training\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for i, img_path in enumerate(img_paths):\n",
    "#             study = re.findall(pattern, img_path)\n",
    "#             img = Image.open(img_path).convert('RGB') #Model expects 3 channels\n",
    "#             img = tforms(img)\n",
    "#             img = img.to(device)\n",
    "#             output = model(img)\n",
    "#             pred = outputs[competition_tasks].cpu().to_numpy()\n",
    "            \n",
    "#             output_csv.iloc[i, 0] = study\n",
    "#             output_csv.iloc[i, 1:5] = pred    \n",
    "        \n",
    "#         model.train(mode=was_training)\n",
    "        \n",
    "#     output_csv.to_csv(output_csv_name, index=False)\n",
    "        \n",
    "        \n",
    "# predict(input_csv_name, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
